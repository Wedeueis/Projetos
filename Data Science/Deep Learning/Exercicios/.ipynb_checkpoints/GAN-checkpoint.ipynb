{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wedeueis/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training set:\t\t55000\n",
      "- Test set:\t\t10000\n",
      "- Validation set:\t5000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#net configuration\n",
    "#conv layer1\n",
    "filter_size1 = 5\n",
    "num_filters1 = 16\n",
    "#conv layer2\n",
    "filter_size2 = 5\n",
    "num_filters2 = 36\n",
    "#dense layer1\n",
    "dense_size = 128\n",
    "\n",
    "#images configuration\n",
    "z_size = 100\n",
    "img_size = 28\n",
    "img_size_flat = img_size*img_size\n",
    "img_shape = (img_size,img_size)\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(input=x, filter=W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        if(reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        #First Conv and Pool Layers\n",
    "        W_conv1 = tf.get_variable('d_wconv1', [5, 5, 1, 8], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv1 = tf.get_variable('d_bconv1', [8], initializer=tf.constant_initializer(0))\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "        h_pool1 = avg_pool_2x2(h_conv1)\n",
    "\n",
    "        #Second Conv and Pool Layers\n",
    "        W_conv2 = tf.get_variable('d_wconv2', [5, 5, 8, 16], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_conv2 = tf.get_variable('d_bconv2', [16], initializer=tf.constant_initializer(0))\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "        h_pool2 = avg_pool_2x2(h_conv2)\n",
    "\n",
    "        #First Fully Connected Layer\n",
    "        W_fc1 = tf.get_variable('d_wfc1', [7 * 7 * 16, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc1 = tf.get_variable('d_bfc1', [32], initializer=tf.constant_initializer(0))\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*16])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        #Second Fully Connected Layer\n",
    "        W_fc2 = tf.get_variable('d_wfc2', [32, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        b_fc2 = tf.get_variable('d_bfc2', [1], initializer=tf.constant_initializer(0))\n",
    "\n",
    "        #Final Layer\n",
    "        y_conv=(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator') as scope:\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        g_dim = 64 #Number of filters of first layer of generator \n",
    "        c_dim = 1 #Color dimension of output (MNIST is grayscale, so c_dim = 1 for us)\n",
    "        s = 28 #Output size of the image\n",
    "        s2, s4, s8, s16 = int(s/2), int(s/4), int(s/8), int(s/16) #We want to slowly upscale the image, so these values will help\n",
    "                                                                  #make that change gradual.\n",
    "\n",
    "        h0 = tf.reshape(z, [batch_size, s16+1, s16+1, 25])\n",
    "        h0 = tf.nn.relu(h0)\n",
    "        #Dimensions of h0 = batch_size x 2 x 2 x 25\n",
    "\n",
    "        #First DeConv Layer\n",
    "        output1_shape = [batch_size, s8, s8, g_dim*4]\n",
    "        W_conv1 = tf.get_variable('g_wconv1', [5, 5, output1_shape[-1], int(h0.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv1 = tf.get_variable('g_bconv1', [output1_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv1 = tf.nn.conv2d_transpose(h0, W_conv1, output_shape=output1_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv1\n",
    "        H_conv1 = tf.contrib.layers.batch_norm(inputs = H_conv1, center=True, scale=True, is_training=True, scope=\"g_bn1\")\n",
    "        H_conv1 = tf.nn.relu(H_conv1)\n",
    "        #Dimensions of H_conv1 = batch_size x 3 x 3 x 256\n",
    "\n",
    "        #Second DeConv Layer\n",
    "        output2_shape = [batch_size, s4 - 1, s4 - 1, g_dim*2]\n",
    "        W_conv2 = tf.get_variable('g_wconv2', [5, 5, output2_shape[-1], int(H_conv1.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv2 = tf.get_variable('g_bconv2', [output2_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv2 = tf.nn.conv2d_transpose(H_conv1, W_conv2, output_shape=output2_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv2\n",
    "        H_conv2 = tf.contrib.layers.batch_norm(inputs = H_conv2, center=True, scale=True, is_training=True, scope=\"g_bn2\")\n",
    "        H_conv2 = tf.nn.relu(H_conv2)\n",
    "        #Dimensions of H_conv2 = batch_size x 6 x 6 x 128\n",
    "\n",
    "        #Third DeConv Layer\n",
    "        output3_shape = [batch_size, s2 - 2, s2 - 2, g_dim*1]\n",
    "        W_conv3 = tf.get_variable('g_wconv3', [5, 5, output3_shape[-1], int(H_conv2.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv3 = tf.get_variable('g_bconv3', [output3_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv3 = tf.nn.conv2d_transpose(H_conv2, W_conv3, output_shape=output3_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='SAME') + b_conv3\n",
    "        H_conv3 = tf.contrib.layers.batch_norm(inputs = H_conv3, center=True, scale=True, is_training=True, scope=\"g_bn3\")\n",
    "        H_conv3 = tf.nn.relu(H_conv3)\n",
    "        #Dimensions of H_conv3 = batch_size x 12 x 12 x 64\n",
    "\n",
    "        #Fourth DeConv Layer\n",
    "        output4_shape = [batch_size, s, s, c_dim]\n",
    "        W_conv4 = tf.get_variable('g_wconv4', [5, 5, output4_shape[-1], int(H_conv3.get_shape()[-1])], \n",
    "                                  initializer=tf.truncated_normal_initializer(stddev=0.1))\n",
    "        b_conv4 = tf.get_variable('g_bconv4', [output4_shape[-1]], initializer=tf.constant_initializer(.1))\n",
    "        H_conv4 = tf.nn.conv2d_transpose(H_conv3, W_conv4, output_shape=output4_shape, \n",
    "                                         strides=[1, 2, 2, 1], padding='VALID') + b_conv4\n",
    "        H_conv4 = tf.nn.tanh(H_conv4)\n",
    "        #Dimensions of H_conv4 = batch_size x 28 x 28 x 1\n",
    "\n",
    "    return H_conv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1]) #Placeholder for input images to the discriminator\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_size]) #Placeholder for input noise vectors to the generator\n",
    "\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dx = discriminator(x_placeholder) #Dx will hold discriminator prediction probabilities for the real MNIST images\n",
    "Gz = generator(z_placeholder, batch_size, z_size) #Gz holds the generated images\n",
    "Dg = discriminator(Gz, reuse=True) #Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.ones_like(Dg))) # ensure forward compatibility: function needs to have logits and labels args explicitly used\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dx, labels = tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = Dg, labels = tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(tf.get_variable_scope().reuse)\n",
    "adam = tf.train.AdamOptimizer(learning_rate=0.0002)\n",
    "trainerD = adam.minimize(d_loss, var_list=d_vars)\n",
    "trainerG = adam.minimize(g_loss, var_list=g_vars, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "INFO:tensorflow:Restoring parameters from checkpoints/mnist_gan/mnist_gan-6000\n",
      "Restored checkpoint from: checkpoints/mnist_gan/mnist_gan-6000\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/mnist_gan/'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "save_path = os.path.join(save_dir, 'mnist_gan')\n",
    "\n",
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "    saver.restore(session, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    dLoss = 0\n",
    "    gLoss = 0\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        z_batch = np.random.normal(-1, 1, size=[batch_size, z_size])\n",
    "        real_image_batch = data.train.next_batch(batch_size)\n",
    "        real_image_batch = np.reshape(real_image_batch[0],[batch_size,28,28,1])\n",
    "    \n",
    "        if dLoss >= 3*gLoss/4:\n",
    "            _, dLoss = session.run([trainerD, d_loss],feed_dict={z_placeholder:z_batch,x_placeholder:real_image_batch}) #Update the discriminator\n",
    "        \n",
    "        i_global,_, gLoss = session.run([global_step, trainerG,g_loss],feed_dict={z_placeholder:z_batch}) #Update the generator \n",
    "        \n",
    "        temp = Gz[0,:,:,:]\n",
    "        print(Gz)\n",
    "        my_i = temp.squeeze()\n",
    "        plt.imshow(my_i, cmap='gray_r')\n",
    "        \n",
    "        if (i_global % 100 == 0) or (i == num_iterations - 1):\n",
    "            msg = \"Global Step: {0:>6}, G losss: {1:>6.1%}, D loss: {2:>6.1%}\"\n",
    "            print(msg.format(i_global, gLoss, dLoss))\n",
    "\n",
    "        if (i_global % 1000 == 0) or (i == num_iterations - 1):\n",
    "            saver.save(session, save_path=save_path, global_step=global_step)\n",
    "\n",
    "            print(\"Saved checkpoint.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'squeeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d7884b69229e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-aa35704a8acc>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(num_iterations)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mi_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainerG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mz_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Update the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mmy_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray_r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'squeeze'"
     ]
    }
   ],
   "source": [
    "optimize(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"generator_9/Tanh:0\", shape=(1, 28, 28, 1), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f95d6a5b080>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADwhJREFUeJzt3X+oXPWZx/HPc5PcqJmA+bHGi3U33SiLIpgsl1iILEoxmKUQ+0ekUUoKpSlYoZUiGxSpCAuh2Sbmj7VwqyGptLbF1jV/6G4krGYLS/GqobEbbUSzTTbxJiZqM4r5+ewf96Rc453vd5xzZs7cPO8XXO7ceebMPJmbzz0z8z3n+zV3F4B4BupuAEA9CD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCm9/LBGo2Gz5s3r5cPCYRy7NgxNZtNa+e2pcJvZrdL2ixpmqTH3X196vbz5s3TunXryjwkgIT165MR/JSOX/ab2TRJ/ypphaTrJa02s+s7vT8AvVXmPf9SSW+5+9vufkrSLyStrKYtAN1WJvxXSTow4eeDxXWfYmZrzWzUzEabzWaJhwNQpTLhn+xDhc+cH+zuI+4+7O7DjUajxMMBqFKZ8B+UdPWEn78g6VC5dgD0SpnwvyzpWjP7opkNSvqapO3VtAWg2zoe6nP3M2Z2r6T/0PhQ3xZ3/0NlnQHoqlLj/O7+nKTnKuoFQA9xeC8QFOEHgiL8QFCEHwiK8ANBEX4gqJ6ez4+LT27FJ7O2Ti1HDdjzA0ERfiAowg8ERfiBoAg/EBThB4JiqA9JuaG6XD03FIj6sOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5w9u3759yfrll1+erM+fPz9Zr/OU3tRjc/wBe34gLMIPBEX4gaAIPxAU4QeCIvxAUIQfCKrUOL+Z7Zd0QtJZSWfcfbiKpvBpubHy06dPt6w9//zzyW3Pnj2brC9atKjU9kNDQ8l6Stmx+NT2zENQzUE+t7r7exXcD4Ae4mU/EFTZ8LukHWb2ipmtraIhAL1R9mX/Mnc/ZGZXSHrBzN5w910Tb1D8UVgrSXPnzi35cACqUmrP7+6Hiu9HJD0jaekktxlx92F3H240GmUeDkCFOg6/mc0ys9nnL0taLun1qhoD0F1lXvYvkPRMMWQyXdLP3f3fK+kKQNd1HH53f1vSjRX2ghYGBtIv0E6ePNmytmvXrpa1drz00kvJ+uzZs5P1995rPQr82GOPJbctOxfAuXPnWtZy4/i55/xiOA6AoT4gKMIPBEX4gaAIPxAU4QeCIvxAUEzd3QO5IavUkJSUH3ZK3X/ZJbZnzpyZrJ84cSJZT9m6dWuyPm/evGR97969yfqHH37YspY72vS+++5L1i+55JJkfSpgzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOPwXkpsceHBxsWXvkkUeS2545cyZZz029NjY2lqw/+OCDLWurV69Obrtz585k/d13303WU89b7pTcDRs2JOsPPfRQsj4VsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5++BstM85873T52TnzvvPDfO//HHHyfrc+bMSdZTxxls3Lgxue3Ro0eT9Vzvqeel2Wwmt12yZEmynvudlp12vBfY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUNlxfjPbIukrko64+w3FdXMl/VLSQkn7Jd3p7u93r83+VnYcv5tjwrmx8Ny8/KdOnUrWU8uDS9Lx48db1tatW5fc9tFHH03W9+3bl6ynTJ+e/q+/atWqju97qmhnz79V0u0XXLdO0k53v1bSzuJnAFNINvzuvkvShX++V0raVlzeJumOivsC0GWdvudf4O6HJan4fkV1LQHoha5/4Gdma81s1MxGc8dTA+idTsM/ZmZDklR8P9Lqhu4+4u7D7j6cWxwRQO90Gv7tktYUl9dIeraadgD0Sjb8ZvaUpP+W9HdmdtDMvilpvaTbzGyfpNuKnwFMIdlxfndvNbn6lyvuZcoqO05f9tzwgYHOP7rJrQkwY8aMZP3999OHd2zdurVlLTdv/4EDB5L13Fh96hiH3BwJOZzPD2DKIvxAUIQfCIrwA0ERfiAowg8ExdTdfSA37JQbyiszrHT69Olk/bLLLkvWL7300mR9xYoVLWu502ZTy3tL0sKFC5P1lNzS4k8//XTH9z1VsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAY5+8D06ZN69p9lz21tOwS3nv27GlZu+eee5LbvvPOO8l6rreUoaGhZH3z5s3J+lQ4ZTeHPT8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4/0UgN/12yuDgYLKem7r7yiuvTNZT4/wvvvhicttbb701We+mi2EcP4c9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ElR3nN7Mtkr4i6Yi731Bc97Ckb0k6WtzsAXd/rltNXuzKLvecmg8gdwxA7nz83JoCufntN23a1LL25JNPJrfNHWOQW3MgJffvuhiW4M5pZ8+/VdLtk1y/yd0XF18EH5hisuF3912SjvegFwA9VOY9/71m9nsz22JmcyrrCEBPdBr+H0taJGmxpMOSftTqhma21sxGzWy02Wx2+HAAqtZR+N19zN3Puvs5ST+RtDRx2xF3H3b34Uaj0WmfACrWUfjNbOLUp1+V9Ho17QDolXaG+p6SdIuk+WZ2UNIPJN1iZosluaT9kr7dxR4BdEE2/O6+epKrn+hCL2ghN+acMjCQfnG3Y8eOZP3mm29O1h9//PFk/e67725ZW7BgQXLbDz74IFlftmxZsr579+6WtZtuuim5be55y/1OyvzOenUMAUf4AUERfiAowg8ERfiBoAg/EBThB4Ji6u4pIDf0kxpWym07NjaWrL/55pvJ+vLly5P11HDdddddl9x2ZGQkWT927Fiynvq3v/baa8lt77rrrmR9+vR0dLr5OyszjDgRe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIpx/h4oOw10mVM8P/roo2T9jTfeSNZTp8W2Y9asWS1ruam5U6cDl3Xy5MlkfcOGDcn6/fffn6znfuep6dZ7hT0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8PlJ2KuZvLReeWqi57bnlqPL3bj13mvm+88caO71vKj+P3wxLf7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKjsOL+ZXS3pp5KulHRO0oi7bzazuZJ+KWmhpP2S7nT397vXar1S47JVzaPeytmzZ5P11Bzy3ZxfXsqfkz9z5syWtVOnTiW3LTtWnur9mmuuKXXf/XA+flnt7PnPSPq+u18n6UuSvmNm10taJ2mnu18raWfxM4ApIht+dz/s7q8Wl09I2ivpKkkrJW0rbrZN0h3dahJA9T7Xe34zWyhpiaTfSVrg7oel8T8Qkq6oujkA3dN2+M2sIenXkr7n7n/+HNutNbNRMxttNpud9AigC9oKv5nN0Hjwf+buvymuHjOzoaI+JOnIZNu6+4i7D7v7cKPRqKJnABXIht/GP/Z8QtJed984obRd0pri8hpJz1bfHoBuaeeU3mWSvi5pj5mdn8f5AUnrJf3KzL4p6U+SVnWnxf7Q7eG8lIGB9N/oVG+Dg4PJbTdu3Jis5067zfVWZttPPvkkWe/mcNzFMJSXkw2/u/9WUqtn+cvVtgOgVzjCDwiK8ANBEX4gKMIPBEX4gaAIPxAUU3f3gTqPIciNledO2c2dbpySO4YgdTpwO1LPaz9MnV039vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/FNAmSmqy45nlz2fP9Vbt49vYCw/jT0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFOH8fKLtMdmr7svddtl5mXn90F78ZICjCDwRF+IGgCD8QFOEHgiL8QFCEHwgqG34zu9rM/tPM9prZH8zsu8X1D5vZ/5nZ7uLrH7vfbkxmlvxKcffkV87AwEDyK9dbmcdGd7VzkM8ZSd9391fNbLakV8zshaK2yd3/pXvtAeiWbPjd/bCkw8XlE2a2V9JV3W4MQHd9rvf8ZrZQ0hJJvyuuutfMfm9mW8xsTott1prZqJmNNpvNUs0CqE7b4TezhqRfS/qeu/9Z0o8lLZK0WOOvDH402XbuPuLuw+4+3Gg0KmgZQBXaCr+ZzdB48H/m7r+RJHcfc/ez7n5O0k8kLe1emwCq1s6n/SbpCUl73X3jhOuHJtzsq5Jer749AN3Szqf9yyR9XdIeM9tdXPeApNVmtliSS9ov6dtd6TCAsqfdAp1o59P+30qa7H/nc9W3A6BXOMIPCIrwA0ERfiAowg8ERfiBoAg/EBRTd/eBfh7H7+feUA57fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iyno5jmtmRyX974Sr5kt6r2cNfD792lu/9iXRW6eq7O1v3P2v2rlhT8P/mQc3G3X34doaSOjX3vq1L4neOlVXb7zsB4Ii/EBQdYd/pObHT+nX3vq1L4neOlVLb7W+5wdQn7r3/ABqUkv4zex2M3vTzN4ys3V19NCKme03sz3FysOjNfeyxcyOmNnrE66ba2YvmNm+4vuky6TV1FtfrNycWFm61ueu31a87vnLfjObJumPkm6TdFDSy5JWu/v/9LSRFsxsv6Rhd699TNjM/kFSU9JP3f2G4rofSjru7uuLP5xz3P2f+qS3hyU16165uVhQZmjiytKS7pD0DdX43CX6ulM1PG917PmXSnrL3d9291OSfiFpZQ199D133yXp+AVXr5S0rbi8TeP/eXquRW99wd0Pu/urxeUTks6vLF3rc5foqxZ1hP8qSQcm/HxQ/bXkt0vaYWavmNnaupuZxIJi2fTzy6dfUXM/F8qu3NxLF6ws3TfPXScrXletjvBPtvpPPw05LHP3v5e0QtJ3ipe3aE9bKzf3yiQrS/eFTle8rlod4T8o6eoJP39B0qEa+piUux8qvh+R9Iz6b/XhsfOLpBbfj9Tcz1/008rNk60srT547vppxes6wv+ypGvN7ItmNijpa5K219DHZ5jZrOKDGJnZLEnL1X+rD2+XtKa4vEbSszX28in9snJzq5WlVfNz128rXtdykE8xlPGopGmStrj7P/e8iUmY2d9qfG8vjc9s/PM6ezOzpyTdovGzvsYk/UDSv0n6laS/lvQnSavcvecfvLXo7RaNv3T9y8rN599j97i3myX9l6Q9ks4VVz+g8ffXtT13ib5Wq4bnjSP8gKA4wg8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/D+OZzdScmLPaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95d6b66dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = generator(z_placeholder, 1, z_size, True)\n",
    "print(sample_image)\n",
    "z_batch = np.random.normal(-1, 1, size=[1, z_size])\n",
    "temp = (session.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
    "my_i = temp.squeeze()\n",
    "plt.imshow(my_i, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
