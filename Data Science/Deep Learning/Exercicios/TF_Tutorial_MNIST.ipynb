{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import prettytensor as pt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "import helper_plot\n",
    "from helper_plot import plot_images\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "Size of:\n",
      "- Training set:\t\t55000\n",
      "- Test set:\t\t10000\n",
      "- Validation set:\t5000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#net configuration\n",
    "#conv layer1\n",
    "filter_size1 = 5\n",
    "num_filters1 = 16\n",
    "#conv layer2\n",
    "filter_size2 = 5\n",
    "num_filters2 = 36\n",
    "#dense layer1\n",
    "dense_size = 128\n",
    "\n",
    "#images configuration\n",
    "img_size = 28\n",
    "img_size_flat = img_size*img_size\n",
    "img_shape = (img_size,img_size)\n",
    "num_channels = 1\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "data = input_data.read_data_sets('data/MNIST/', one_hot=True)\n",
    "data.test.cls = np.argmax(data.test.labels, axis=1)\n",
    "\n",
    "print(\"Size of:\")\n",
    "print(\"- Training set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Test set:\\t\\t{}\".format(len(data.test.labels)))\n",
    "print(\"- Validation set:\\t{}\".format(len(data.validation.labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None,img_size_flat], name='x')\n",
    "x_images = tf.reshape(x, [-1,img_size,img_size,num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None,num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_network(images, training):\n",
    "    x_pretty = pt.wrap(images)\n",
    "    if training:\n",
    "        phase = pt.Phase.train\n",
    "    else:\n",
    "        phase = pt.Phase.infer\n",
    "        \n",
    "    with pt.defaults_scope(activation_fn=tf.nn.relu, phase=phase):\n",
    "        y_pred, loss = x_pretty.\\\n",
    "            conv2d(kernel=filter_size1, depth=num_filters1, name='layer_conv1').\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            conv2d(kernel=filter_size2, depth=num_filters2, name='layer_conv2').\\\n",
    "            max_pool(kernel=2, stride=2).\\\n",
    "            flatten().\\\n",
    "            fully_connected(size=dense_size, name='layer_fc1').\\\n",
    "            fully_connected(size=dense_size, name='layer_fc2').\\\n",
    "            softmax_classifier(num_classes=num_classes, labels=y_true)\n",
    "        \n",
    "    return  y_pred, loss\n",
    "\n",
    "def create_network(images, training):\n",
    "    with tf.variable_scope('network', reuse=not training):\n",
    "         y_pred, loss = main_network(images=images, training=training)\n",
    "    return y_pred, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "_, loss = create_network(x_images, training=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, _ = create_network(x_images, training=False)\n",
    "y_pred_cls = tf.argmax(y_pred, axis=1)\n",
    "correct_pred = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to restore last checkpoint ...\n",
      "Failed to restore checkpoint. Initializing variables instead.\n"
     ]
    }
   ],
   "source": [
    "session = tf.Session()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "save_dir = 'checkpoints/mnist'\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "save_path = os.path.join(save_dir, 'mnist_cnn')\n",
    "\n",
    "try:\n",
    "    print(\"Trying to restore last checkpoint ...\")\n",
    "    last_chk_path = tf.train.latest_checkpoint(checkpoint_dir=save_dir)\n",
    "    saver.restore(session, save_path=last_chk_path)\n",
    "    print(\"Restored checkpoint from:\", last_chk_path)\n",
    "except:\n",
    "    print(\"Failed to restore checkpoint. Initializing variables instead.\")\n",
    "    session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        x_batch, y_true_batch = data.train.next_batch(train_batch_size)\n",
    "            \n",
    "        feed_dict_train = {x: x_batch, y_true: y_true_batch}\n",
    "        \n",
    "        i_global, _ = session.run([global_step, optimizer], feed_dict=feed_dict_train)\n",
    "        \n",
    "        if (i_global%100 == 0) or (i == num_iterations - 1):\n",
    "            batch_acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "            msg = \"Global Step: {0:>6}, Training Batch Accuracy: {1:>6.1%}\"\n",
    "            print(msg.format(i_global, batch_acc))\n",
    "            \n",
    "        if (i_global%1000 == 0) or (i == num_iterations - 1):\n",
    "            saver.save(session, save_path=save_path, global_step=global_step)\n",
    "            print(\"Saved checkpoint\")\n",
    "            \n",
    "    end_time = time.time()\n",
    "    time_diff = end_time - start_time\n",
    "    \n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_diff)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 16\n",
    "\n",
    "def print_test_accuracy():\n",
    "\n",
    "    num_test = len(data.test.images)\n",
    "\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + test_batch_size, num_test)\n",
    "\n",
    "        images = data.test.images[i:j, :]\n",
    "        labels = data.test.labels[i:j, :]\n",
    "\n",
    "        feed_dict = {x: images, y_true: labels}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        \n",
    "        i = j\n",
    "\n",
    "    cls_true = data.test.cls\n",
    "    correct = (cls_true == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 97.0% (9696 / 10000)\n"
     ]
    }
   ],
   "source": [
    " print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Step:   1100, Training Batch Accuracy:  98.4%\n",
      "Global Step:   1200, Training Batch Accuracy:  93.8%\n",
      "Global Step:   1300, Training Batch Accuracy:  93.8%\n",
      "Global Step:   1400, Training Batch Accuracy:  98.4%\n",
      "Global Step:   1500, Training Batch Accuracy: 100.0%\n",
      "Global Step:   1600, Training Batch Accuracy: 100.0%\n",
      "Global Step:   1700, Training Batch Accuracy:  96.9%\n",
      "Global Step:   1800, Training Batch Accuracy:  98.4%\n",
      "Global Step:   1900, Training Batch Accuracy:  98.4%\n",
      "Global Step:   2000, Training Batch Accuracy:  96.9%\n",
      "Saved checkpoint\n",
      "Time usage: 0:00:20\n"
     ]
    }
   ],
   "source": [
    "optimize(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test-Set: 98.2% (9825 / 10000)\n"
     ]
    }
   ],
   "source": [
    " print_test_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
